{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 150 + 4 +1\n",
    "batch_size = 128\n",
    "n_layer = 8 \n",
    "n_head = 8\n",
    "n_embd = 256\n",
    "max_epochs = 10\n",
    "\n",
    "# test_every_iteration = 20000 ## we test every epoch\n",
    "\n",
    "stop_token = '$'\n",
    "split_token = '&'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/06/2021 20:27:20 - INFO - rdkit -   Enabling RDKit 2020.09.1 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "\n",
    "# from flattenV3Advanced import flattenData\n",
    "\n",
    "# make deterministic\n",
    "from minGPT.mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = torch.cuda.current_device()\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "from minGPT.mingpt.model import GPT, GPTConfig\n",
    "# from minGPT.mingpt.trainer import Trainer, TrainerConfig\n",
    "# from minGPT.mingpt.utils import sample\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from rdkit.Chem.rdMolDescriptors import CalcMolFormula\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.rdBase import BlockLogs\n",
    "from rdkit.Chem import PandasTools\n",
    "block = BlockLogs() ## not sure we want to block all but rdkit complain when wrong smiles are sent...\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "## dataset path\n",
    "data_path = '/home/teleport/perso/smiles_clean.db'\n",
    "EXPERIMENT = '20210105_DF_gpt_smiles_pcba_first'\n",
    "experiment_path = \"/opt/data/train_dir/\" + EXPERIMENT + \"/\"\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.mkdir(experiment_path)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains and tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINS Task: overwriting (reusing) task id=c1a099fcff034127a4bc24580ce9e4b0\n",
      "TRAINS results page: http://172.22.4.157:8080/projects/8f2ac9400a46477683280746b293e09f/experiments/c1a099fcff034127a4bc24580ce9e4b0/output/log\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "writer = SummaryWriter(experiment_path + '/' + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "from trains import Task\n",
    "import trains\n",
    "task = Task.init(project_name='gpt_smiles', task_name=EXPERIMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created and Successfully Connected to SQLite\n"
     ]
    }
   ],
   "source": [
    "sqliteConnection = sqlite3.connect(data_path)\n",
    "cursor = sqliteConnection.cursor()\n",
    "print(\"Database created and Successfully Connected to SQLite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6260429,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT COUNT() FROM pcba_train')\n",
    "n_train = cursor.fetchone()\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585833,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT COUNT() FROM pcba_test')\n",
    "n_test = cursor.fetchone()\n",
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06 20:27:22,872 - trains.Repository Detection - WARNING - Can't get branch information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(=O)Nc1ccc(C(=O)OCC(=O)NC(=O)NC(C)(C)C)cc1</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[N+]1(C)[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1noc(NS(=O)(=O)c2ccc(N)cc2)c1C</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cc1ccc(NCCC(=O)c2cccs2)cc1</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oc1ccccc1CNCc1ccccc1O</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C/C(CCN1CCCCc2nc(C)c(C)cc21)=N\\O[C@H](C)c1cn([...</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCOC(=O)c1c(NC(=O)c2cc(C)oc2C)sc(C(=O)Nc2ccc(C...</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C=CCOc1cc(OC)c(OC)c(OC)c1</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COc1ccc(CC(=O)NCc2nnc(SCC(=O)Nc3nccs3)n2C)cc1</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cc1ccccc1NC(=O)Cn1nnc2c(cnn2-c2ccc(F)cc2)c1=O</td>\n",
       "      <td>PCBA.1030</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1  2   3\n",
       "0       CC(=O)Nc1ccc(C(=O)OCC(=O)NC(=O)NC(C)(C)C)cc1  PCBA.1030  0   1\n",
       "1  C[N+]1(C)[C@H]2CC[C@@H]1CC(OC(=O)C(CO)c1ccccc1)C2  PCBA.1030  0   2\n",
       "2                   Cc1noc(NS(=O)(=O)c2ccc(N)cc2)c1C  PCBA.1030  0   3\n",
       "3                         Cc1ccc(NCCC(=O)c2cccs2)cc1  PCBA.1030  1   4\n",
       "4                              Oc1ccccc1CNCc1ccccc1O  PCBA.1030  0   5\n",
       "5  C/C(CCN1CCCCc2nc(C)c(C)cc21)=N\\O[C@H](C)c1cn([...  PCBA.1030  0   6\n",
       "6  CCOC(=O)c1c(NC(=O)c2cc(C)oc2C)sc(C(=O)Nc2ccc(C...  PCBA.1030  0   7\n",
       "7                          C=CCOc1cc(OC)c(OC)c(OC)c1  PCBA.1030  0   8\n",
       "8      COc1ccc(CC(=O)NCc2nnc(SCC(=O)Nc3nccs3)n2C)cc1  PCBA.1030  0   9\n",
       "9      Cc1ccccc1NC(=O)Cn1nnc2c(cnn2-c2ccc(F)cc2)c1=O  PCBA.1030  0  10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM pcba_train LIMIT 10')\n",
    "x = cursor.fetchall()\n",
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06 20:27:22,897 - trains.Repository Detection - WARNING - Can't get commit information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n",
      "2021-01-06 20:27:22,908 - trains.Repository Detection - WARNING - Can't get root information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n",
      "2021-01-06 20:27:22,918 - trains.Repository Detection - WARNING - Can't get status information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n",
      "2021-01-06 20:27:22,939 - trains.Repository Detection - WARNING - Can't get diff information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n",
      "2021-01-06 20:27:22,949 - trains.Repository Detection - WARNING - Can't get modified information for git repo in /home/teleport/.conda/envs/pytorch_smiles/lib/python3.8/site-packages\n",
      "TRAINS new package available: UPGRADE to v0.17.2 is recommended!\n",
      "Release Notes:\n",
      "Trains is now ClearML! We recommend upgrading to the latest ClearML SDK version :)\n",
      "This new version is ClearML, install using 'pip install clearml'\n",
      "\n",
      "Bug Fixes\n",
      "\n",
      "- Fix broken `clearml-task` CLI\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PCBA.1030',\n",
       " 'PCBA.1458',\n",
       " 'PCBA.1460',\n",
       " 'PCBA.2546',\n",
       " 'PCBA.2551',\n",
       " 'PCBA.485297',\n",
       " 'PCBA.485313',\n",
       " 'PCBA.485364',\n",
       " 'PCBA.504332',\n",
       " 'PCBA.504333',\n",
       " 'PCBA.504339',\n",
       " 'PCBA.504444',\n",
       " 'PCBA.504467',\n",
       " 'PCBA.588342',\n",
       " 'PCBA.624296',\n",
       " 'PCBA.624297',\n",
       " 'PCBA.624417',\n",
       " 'PCBA.651965',\n",
       " 'PCBA.652104',\n",
       " 'PCBA.686970',\n",
       " 'PCBA.686978',\n",
       " 'PCBA.686979',\n",
       " 'PCBA.720504']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT DISTINCT variable FROM pcba_train')\n",
    "tasks = cursor.fetchall()\n",
    "tasks = [i[0] for i in tasks]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (sqliteConnection):\n",
    "    sqliteConnection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['C','c','N','n','O','o','H','B','r','l','I','F','S','s','P','.','[',']','(',')','-','+','=','@','/','\\\\','#','$','&']\n",
    "word_list += list(string.digits)\n",
    "word_list += tasks\n",
    "stoi = { ch:i for i,ch in enumerate(word_list) }\n",
    "itos = { i:ch for i,ch in enumerate(word_list) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for checking the smiles and tokenize them, detokenize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('asdpajsdpsd'[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_idx(data, idx, stoi, block_size = None, stop_token = '$', split_token = '&'):\n",
    "#     return tokenize_smiles(data['smiles'][idx],data['MolFormula'][idx],data['logp'][idx], stoi, block_size=block_size, stop_token = '$', split_token = '&')\n",
    "\n",
    "def tokenize_smiles(smiles, task, results, stoi, block_size = None, stop_token = '$', split_token = '&'):\n",
    "    chunk = []\n",
    "    chunk.append(task)\n",
    "    for i in split_token + str(results) + split_token + smiles + stop_token:\n",
    "        chunk.append(i)\n",
    "    if block_size is not None:\n",
    "        while len(chunk) < block_size:\n",
    "            chunk.append(stop_token)\n",
    "        if len(chunk) > block_size:\n",
    "            chunk = chunk[:block_size]\n",
    "    data = [stoi[s] for s in chunk]\n",
    "    return data\n",
    "\n",
    "def y_to_completion(y, itos):\n",
    "    return ''.join([itos[int(i)] for i in y])\n",
    "    \n",
    "    \n",
    "def check_model_output(model, task, results, stop_token = '$', split_token = '&', batch_size = 4,temperature=0.9):\n",
    "    completions = []\n",
    "    for i, j  in zip(task, results):        \n",
    "        data = [stoi[s] for s in [i , split_token , j , split_token]]\n",
    "        x = [torch.tensor(data, dtype=torch.long).unsqueeze(0).to(device)]\n",
    "        y = sample_clean(model, x, steps = block_size, temperature=temperature, sample=True, top_k=5, itos = itos, stop_token = '$', batch_size = batch_size)\n",
    "        for idx in range(y.size(0)):    \n",
    "            completion = y_to_completion(y[idx], itos)\n",
    "            completions.append(completion)\n",
    "    df = completion_to_pandas(completions)\n",
    "            \n",
    "    return df, completions\n",
    "    \n",
    "def completion_to_pandas(completion):\n",
    "    smiles = []\n",
    "    task = []\n",
    "    result = []\n",
    "    MolFormulaOutput = []\n",
    "    for i in completion:\n",
    "#         print(i)\n",
    "        i = i.split(split_token)\n",
    "        task.append(i[0])\n",
    "        result.append(i[1])\n",
    "        smile = i[2].split(stop_token)[0]\n",
    "        smiles.append(smile)\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol is None:\n",
    "            MolFormulaOutput.append('fail')\n",
    "        else:\n",
    "            MolFormulaOutput.append(CalcMolFormula(mol))\n",
    "    df = pd.DataFrame(list(zip(task,result, smiles, MolFormulaOutput)), \n",
    "               columns =['task','result', 'smiles', 'MolFormulaOutput']) \n",
    "    PandasTools.AddMoleculeColumnToFrame(df,smilesCol='smiles')\n",
    "    return(df)\n",
    "\n",
    "def check_df(df):\n",
    "    df2 = df[df['MolFormulaOutput'] != 'fail']\n",
    "    smiles_failure_ratio = (len(df) - len(df2))/len(df)\n",
    "    return {'smiles_failure_ratio':smiles_failure_ratio}\n",
    "\n",
    "\n",
    "# def add_mol(writer, smiles, global_step=None, size=(300, 300)):\n",
    "#     \"\"\"\n",
    "#     Adds a molecule to the images section of Tensorboard.\n",
    "#     \"\"\"\n",
    "#     img_transform = transforms.Compose([\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "#     mol = Chem.MolFromSmiles(smiles)\n",
    "#     image = Chem.Draw.MolToImage(mol, size=size)\n",
    "#     writer.add_image(smiles, img_transform(image), global_step) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = 'CC(=O)Nc1ccc(C(=O)OCC(=O)NC(=O)NC(C)(C)C)cc1'\n",
    "task = 'PCBA.1030'\n",
    "result = 0\n",
    "df = tokenize_smiles(smiles, task, result, stoi, block_size)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smiles_failure_ratio': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = 'truc&1&CN(C)c1ccc(CNC(=O)CN2CCC(C)(CN3CCN(C)CC3)CC2)cc1$$$$'\n",
    "check_df(completion_to_pandas([completion]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([39, 28, 29, 28,  0,  0,  0,  2, 30,  0,  0,  0, 18,  2, 18,  0, 19,  0,\n",
       "          0,  1, 31,  1,  1,  1, 18,  4,  0, 19,  1, 18,  4,  0, 19,  1, 31, 19,\n",
       "          0,  0, 30, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27]),\n",
       " tensor([28, 29, 28,  0,  0,  0,  2, 30,  0,  0,  0, 18,  2, 18,  0, 19,  0,  0,\n",
       "          1, 31,  1,  1,  1, 18,  4,  0, 19,  1, 18,  4,  0, 19,  1, 31, 19,  0,\n",
       "          0, 30, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "         27, 27, 27, 27, 27, 27, 27, 27, 27, 27]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SmilesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, table, n, id_string, block_size, stoi, itos):\n",
    "        \n",
    "        self.table = table\n",
    "        self.n = n\n",
    "        self.id_string = id_string\n",
    "        self.stoi = stoi\n",
    "        self.itos = itos\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = len(self.stoi)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx,verbose=False):\n",
    "        try:\n",
    "            sqliteConnection = sqlite3.connect(data_path)\n",
    "            cursor = sqliteConnection.cursor()\n",
    "            sqlite_select_Query = \"SELECT * FROM \" + self.table + \"  WHERE \" + self.id_string + \" = \" + str(idx+1)\n",
    "            cursor.execute(sqlite_select_Query)\n",
    "            record = cursor.fetchone()\n",
    "            if (sqliteConnection):\n",
    "                sqliteConnection.close()\n",
    "#             print(record[5])\n",
    "            smiles = record[0]\n",
    "            task = record[1]\n",
    "            result = record[2]\n",
    "            converted_chunk = tokenize_smiles(smiles, task, result, self.stoi, self.block_size)\n",
    "        except:\n",
    "#             print('error in data loader: idx = ' + str(idx))\n",
    "#             try:\n",
    "#                 print(record)\n",
    "#             except:\n",
    "#                 print('could not even print record')\n",
    "            return self.__getitem__(random.randint(0, self.n))\n",
    "        x = torch.tensor(converted_chunk[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(converted_chunk[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "            \n",
    "train_dataset = SmilesDataset('pcba_train', n_train[0], 'id', block_size, stoi, itos) \n",
    "test_dataset = SmilesDataset('pcba_test', n_test[0], 'id', block_size, stoi, itos) \n",
    "\n",
    "df = train_dataset.__getitem__(idx = 10,verbose=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqliteConnection = sqlite3.connect(data_path)\n",
    "# cursor = sqliteConnection.cursor()\n",
    "# sqlite_select_Query = \"SELECT * FROM \" + 'smiles_train' + \"  WHERE \" + 'id' + \" = \" + str(61678207+1)\n",
    "# cursor.execute(sqlite_select_Query)\n",
    "# record = cursor.fetchone()\n",
    "# print(record)\n",
    "# if (sqliteConnection):\n",
    "#     sqliteConnection.close()\n",
    "# #             print(record[5])\n",
    "# smiles = record[1]\n",
    "# molecular_formula = record[5]\n",
    "# logp = record[3]\n",
    "# # converted_chunk = tokenize_smiles(smiles, molecular_formula, logp, self.stoi, self.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqliteConnection = sqlite3.connect('/home/teleport/perso/smiles.db')\n",
    "# cursor = sqliteConnection.cursor()\n",
    "# sqlite_select_Query = \"SELECT * FROM \" + 'smiles_test' + \"  WHERE \" + 'id' + \" = \" + str(1)\n",
    "# cursor.execute(sqlite_select_Query)\n",
    "# record = cursor.fetchone()\n",
    "# print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/06/2021 20:27:23 - INFO - minGPT.mingpt.model -   number of parameters: 6.390016e+06\n"
     ]
    }
   ],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=n_layer, n_head=n_head, n_embd=n_embd)\n",
    "model = GPT(mconf)\n",
    "# model.load_state_dict(torch.load(experiment_path + 'model_0.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_logits(logits, k):\n",
    "    v, ix = torch.topk(logits, k)\n",
    "    out = logits.clone()\n",
    "    out[out < v[:, [-1]]] = -float('Inf')\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_clean(model, xs, steps, temperature=1.0, sample=False, top_k=None, itos = None, stop_token = '$',batch_size = 4):\n",
    "#     block_size = model.get_block_size()\n",
    "    model.eval()\n",
    "    xs = sorted(xs, key = lambda x: x.size(1))\n",
    "    ## add the batch size\n",
    "    xs = [torch.cat(batch_size*[x]) for x in xs]\n",
    "    \n",
    "    ## start by making them the same length\n",
    "    x = xs[0]\n",
    "    for i in range(1,len(xs)): # nothing to do if length 1\n",
    "        while x.size(1) < xs[i].size(1):\n",
    "            x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
    "            logits, _ = model(x_cond)\n",
    "            # pluck the logits at the final step and scale by temperature\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            # optionally crop probabilities to only the top k options\n",
    "            if top_k is not None:\n",
    "                logits = top_k_logits(logits, top_k)\n",
    "            # apply softmax to convert to probabilities\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # sample from the distribution or take the most likely\n",
    "            if sample:\n",
    "                ix = torch.multinomial(probs, num_samples=1)\n",
    "            else:\n",
    "                _, ix = torch.topk(probs, k=1, dim=-1)\n",
    "            # append to the sequence and continue\n",
    "            x = torch.cat((x, ix), dim=1)\n",
    "        x= torch.cat((x,xs[i]), dim=0)\n",
    "    \n",
    "    \n",
    "    ## now we can keep going...\n",
    "    keep_going = True\n",
    "    while keep_going:\n",
    "#         print(x.size(1))\n",
    "        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
    "        logits, _ = model(x_cond)\n",
    "        # pluck the logits at the final step and scale by temperature\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop probabilities to only the top k options\n",
    "        if top_k is not None:\n",
    "            logits = top_k_logits(logits, top_k)\n",
    "        # apply softmax to convert to probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # sample from the distribution or take the most likely\n",
    "        if sample:\n",
    "            ix = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
    "        # append to the sequence and continue\n",
    "        x = torch.cat((x, ix), dim=1)\n",
    "        if x.size(1) == block_size:\n",
    "            keep_going = False\n",
    "        if itos is not None:\n",
    "            sequences_over = 0\n",
    "            for i in range(x.size(0)):                \n",
    "                if itos[int(ix[i])] == stop_token:\n",
    "                    sequences_over += 1\n",
    "            if sequences_over == x.size(0):\n",
    "                keep_going = False\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    max_epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 3e-4\n",
    "    betas = (0.9, 0.95)\n",
    "    grad_norm_clip = 1.0\n",
    "    weight_decay = 0.1 # only applied on matmul weights\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay = False\n",
    "    warmup_tokens = 375e6 # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n",
    "    final_tokens = 260e9 # (at what point we reach 10% of original LR)\n",
    "    # checkpoint settings\n",
    "    ckpt_path = None\n",
    "    num_workers = 0 # for DataLoader\n",
    "#     test_every_iteration = 50000\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, train_dataset, test_dataset, config):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.config = config\n",
    "\n",
    "        # take over whatever gpus are on the system\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = torch.nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        # DataParallel wrappers keep raw model object in .module attribute\n",
    "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        logger.info(\"saving %s\", self.config.ckpt_path)\n",
    "        torch.save(raw_model.state_dict(), self.config.ckpt_path + 'model.pt')\n",
    "\n",
    "    def train(self, writer):\n",
    "        model, config = self.model, self.config\n",
    "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
    "        optimizer = raw_model.configure_optimizers(config)\n",
    "\n",
    "        def run_epoch(split, epoch):\n",
    "            is_train = split == 'train'\n",
    "            model.train(is_train)\n",
    "            data = self.train_dataset if is_train else self.test_dataset\n",
    "            loader = DataLoader(data, shuffle=True, pin_memory=True,\n",
    "                                batch_size=config.batch_size,\n",
    "                                num_workers=config.num_workers)\n",
    "\n",
    "            losses = []\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
    "            for it, (x, y) in pbar:\n",
    "\n",
    "                # place data on the correct device\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # forward the model\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    logits, loss = model(x, y)\n",
    "                    loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
    "                    losses.append(loss.item())\n",
    "\n",
    "                if is_train:\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # decay the learning rate based on our progress\n",
    "                    if config.lr_decay:\n",
    "                        self.tokens += (y >= 0).sum() # number of tokens processed this step (i.e. label is not -100)\n",
    "                        if self.tokens < config.warmup_tokens:\n",
    "                            # linear warmup\n",
    "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
    "                        else:\n",
    "                            # cosine learning rate decay\n",
    "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
    "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "                        lr = config.learning_rate * lr_mult\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "                    else:\n",
    "                        lr = config.learning_rate\n",
    "\n",
    "                    # report progress\n",
    "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
    "                                        \n",
    "\n",
    "            if not is_train:\n",
    "                test_loss = float(np.mean(losses))\n",
    "                logger.info(\"test loss: %f\", test_loss)\n",
    "                return test_loss\n",
    "            else:\n",
    "                train_loss = float(np.mean(losses))\n",
    "                return train_loss\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        self.tokens = 0 # counter used for learning rate decay\n",
    "        for epoch in range(config.max_epochs):\n",
    "\n",
    "            train_loss = run_epoch('train', epoch)\n",
    "            x = (epoch+1) * len(self.train_dataset)# + it * self.config.batch_size\n",
    "            writer.add_scalar('loss/train_loss',train_loss,x)\n",
    "            if self.test_dataset is not None:\n",
    "                test_loss = run_epoch('test', epoch)\n",
    "                \n",
    "                \n",
    "                writer.add_scalar('loss/test_loss',test_loss,x)\n",
    "                tasks = self.config.tasks\n",
    "                results = self.config.results\n",
    "                df, completions = check_model_output(model, tasks, results, batch_size = 16)  \n",
    "                results = check_df(df)\n",
    "                for i in ['smiles_failure_ratio']:\n",
    "                    writer.add_scalar('results/'+i,results[i],x)\n",
    "            \n",
    "                self.save_checkpoint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in ('0' * len(tasks))+('1' * len(tasks)):\n",
    "    results.append(i)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, completions = check_model_output(model, tasks*2, results, batch_size = 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 962: train loss 0.22068. lr 6.000000e-04:   2%|▏         | 963/48910 [02:58<2:30:44,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINS Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 1758: train loss 0.19245. lr 6.000000e-04:   4%|▎         | 1759/48910 [05:29<2:29:23,  5.26it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# # initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset)*block_size,\n",
    "                      num_workers=2, ckpt_path = experiment_path,\n",
    "                      tasks = tasks * 2, results = results) ## 10000 * 128 = 1M approx\n",
    "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
    "trainer.train(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, completions = check_model_output(model, tasks*2, results, batch_size = 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_smiles",
   "language": "python",
   "name": "pytorch_smiles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
